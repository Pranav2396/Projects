{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GEutyvKHb3hd",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow\n",
    "!pip install -q sklearn\n",
    "!pip install -q torch\n",
    "!pip install -q pretrainedmodels\n",
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "kEfCahUVFGvF",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JCfij5DIWEq1",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "#import pretrainedmodels\n",
    "import torch\n",
    "#import pretrainedmodels.utils as utils\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "############################################Encoder#################################################\n",
    "model_name = 'vgg16' # could be fbresnet152 or inceptionresnetv2\n",
    "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "print(pretrainedmodels.pretrained_settings[model_name])\n",
    "model.eval()\n",
    "\n",
    "with open('./8/8/8.txt') as f:\n",
    "    content = [x.strip('\\n') for x in f.readlines()]\n",
    "\n",
    "print(content[0].split(\"|\")[0])\n",
    "str1='./8/train_8/'\n",
    "\n",
    "data_input=[]\n",
    "data_output=[]\n",
    "\n",
    "for i in range(0,len(content)):\n",
    "    try:\n",
    "        str2=content[i].split(\"|\")[0]\n",
    "        str3=str1+str2\n",
    "        #print(str3)\n",
    "        load_img = utils.LoadImage()\n",
    "\n",
    "        # transformations depending on the model\n",
    "        # rescale, center crop, normalize, and others (ex: ToBGR, ToRange255)\n",
    "        tf_img = utils.TransformImage(model)\n",
    "\n",
    "        path_img = str3\n",
    "\n",
    "        input_img = load_img(path_img)\n",
    "        input_tensor = tf_img(input_img) \n",
    "        input_tensor = input_tensor.unsqueeze(0)  \n",
    "        input = torch.autograd.Variable(input_tensor,\n",
    "                                        requires_grad=False)\n",
    "\n",
    "        features = model.features(input)\n",
    "        features = torch.Tensor.detach(features).numpy()\n",
    "        data_input.append(features[0])\n",
    "        capt=content[i].split(\"|\")[2].lstrip()\n",
    "        data_output.append(capt)\n",
    "\n",
    "        if(i%100==0):\n",
    "            print(i)\n",
    "\n",
    "        if(i%1000==0):\n",
    "          np.savez('data_input_vgg.npz', name1=data_input)\n",
    "          np.savez('data_output_vgg.npz', name1=data_output)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#Normalization\n",
    "data_input=np.array(data_input)\n",
    "print(data_input)\n",
    "for i in range (0,4096):\n",
    "   data_input[:,i]=minmax_scale(data_input[:,i])\n",
    "\n",
    "print(data_input[0])\n",
    "print(data_input[1])\n",
    "data_input=np.load('/content/gdrive/My Drive/feats.npy','r')\n",
    "\n",
    "data_input=np.load('/content/gdrive/My Drive/data_input_goog_train_4.npz')['name1']\n",
    "data_output=np.load('/content/gdrive/My Drive/data_output_vgg.npz')['name1']\n",
    "\n",
    "data_input_test=np.load('/content/gdrive/My Drive/data_input_goog_test_4.npz')['name1']\n",
    "data_output_test=np.load('/content/gdrive/My Drive/data_output_vgg_test.npz')['name1']\n",
    "\n",
    "feats_test=data_input_test\n",
    "captions_test=data_output_test\n",
    "\n",
    "feats_tot=data_input\n",
    "captions_tot=data_output\n",
    "\n",
    "feats=feats_tot\n",
    "captions=captions_tot\n",
    "\n",
    "print(data_output[0])\n",
    "\n",
    "# print(data_input[10],data_output[10])\n",
    "# print(data_input1[10],data_output1[10])\n",
    "# print(len(data_input),len(data_input[0]))\n",
    "# print(len(data_output),len(data_output[0]))\n",
    "\n",
    "############################################################Decoder################################\n",
    "\n",
    "model_path = '/content/gdrive/My Drive/models/tensorflow'\n",
    "\n",
    "#################Processing words###############\n",
    "def preProBuildWordVocab(sentence_iterator, word_count_threshold=15): \n",
    "    print('preprocessing %d word vocab' % (word_count_threshold, ))\n",
    "    word_counts = {}\n",
    "    nsents = 0\n",
    "    for sent in sentence_iterator:\n",
    "      nsents += 1\n",
    "      for w in sent.lower().split(' '):\n",
    "        word_counts[w] = word_counts.get(w, 0) + 1\n",
    "    vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "    print('preprocessed words %d -> %d' % (len(word_counts), len(vocab)))\n",
    "\n",
    "    ixtoword = {}\n",
    "    ixtoword[0] = '.'\n",
    "    wordtoix = {}\n",
    "    wordtoix['#START#'] = 0\n",
    "    ix = 1\n",
    "    for w in vocab:\n",
    "      wordtoix[w] = ix\n",
    "      ixtoword[ix] = w\n",
    "      ix += 1\n",
    "\n",
    "    word_counts['.'] = nsents\n",
    "    bias_init_vector = np.array([1.0*word_counts[ixtoword[i]] for i in ixtoword])\n",
    "    bias_init_vector /= np.sum(bias_init_vector)\n",
    "    bias_init_vector = np.log(bias_init_vector)\n",
    "    bias_init_vector -= np.max(bias_init_vector)\n",
    "    return wordtoix, ixtoword, bias_init_vector.astype(np.float32)\n",
    "\n",
    "\n",
    "class Captions():\n",
    "    \n",
    "    def initialize_param(self,init_b):\n",
    "        with tf.device('/cpu:0'):\n",
    "            self.word_embedding = tf.Variable(tf.random_uniform([self.n_words, self.dim_embed], -0.1, 0.1))\n",
    "\n",
    "            self.embedding_bias = tf.Variable(tf.zeros([dim_embed]))\n",
    "            self.lstm = tf.contrib.rnn.BasicLSTMCell(dim_hidden)\n",
    "\n",
    "            self.img_embedding = tf.Variable(tf.random_uniform([dim_in, dim_hidden], -0.1, 0.1))\n",
    "            self.img_embedding_bias = tf.Variable(tf.zeros([dim_hidden]))\n",
    "\n",
    "            self.word_encoding = tf.Variable(tf.random_uniform([dim_hidden, self.n_words], -0.1, 0.1))\n",
    "            \n",
    "            if init_b is not None:\n",
    "              self.word_encoding_bias = tf.Variable(init_b)\n",
    "            else:\n",
    "              self.word_encoding_bias = tf.Variable(tf.zeros([n_words]))\n",
    " \n",
    "\n",
    "    def __init__(self,dim_in, dim_embed, dim_hidden, batch_size,steps, n_words, init_b):\n",
    "\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_embed = dim_embed\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.batch_size = batch_size\n",
    "        self.n_lstm_steps = steps\n",
    "        self.n_words = n_words\n",
    "\n",
    "        self.initialize_param(init_b)\n",
    "        \n",
    "    def build_model(self):\n",
    "            caption_placeholder = tf.placeholder(tf.int32, [self.batch_size, self.n_lstm_steps])\n",
    "            mask = tf.placeholder(tf.float32, [self.batch_size, self.n_lstm_steps])\n",
    "\n",
    "            img = tf.placeholder(tf.float32, [self.batch_size, self.dim_in])\n",
    "\n",
    "            image_embedding = tf.matmul(img, self.img_embedding) + self.img_embedding_bias\n",
    "\n",
    "            state = self.lstm.zero_state(self.batch_size, dtype=tf.float32)\n",
    "\n",
    "            total_loss = 0.0\n",
    "            \n",
    "            with tf.variable_scope(\"RNN\"):\n",
    "                i=0\n",
    "                while(i<self.n_lstm_steps):\n",
    "                    if i > 0:\n",
    "                        with tf.device('/cpu:0'):\n",
    "                          current_embedding = tf.nn.embedding_lookup(self.word_embedding,caption_placeholder[:, i - 1]) + self.embedding_bias\n",
    "                          tf.get_variable_scope().reuse_variables()\n",
    "                    else:\n",
    "                        current_embedding = image_embedding\n",
    "                        \n",
    "                    out, state = self.lstm(current_embedding, state)\n",
    "\n",
    "                    if i > 0:\n",
    "                        labels = tf.expand_dims(caption_placeholder[:, i], 1)\n",
    "                        ix_range = tf.range(0, self.batch_size, 1)\n",
    "                        ixs = tf.expand_dims(ix_range, 1)\n",
    "                        concat = tf.concat([ixs, labels], 1)\n",
    "                        onehot = tf.sparse_to_dense(\n",
    "                            concat, tf.stack([self.batch_size, self.n_words]), 1.0, 0.0)\n",
    "\n",
    "                        logit = tf.matmul(out, self.word_encoding) + self.word_encoding_bias\n",
    "                        xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=onehot)\n",
    "                        xentropy = xentropy * mask[:, i]\n",
    "\n",
    "                        loss = tf.reduce_sum(xentropy)\n",
    "                        total_loss += loss\n",
    "                    \n",
    "                    i=i+1\n",
    "\n",
    "                total_loss = total_loss / tf.reduce_sum(mask[:, 1:])\n",
    "                return total_loss, img, caption_placeholder, mask\n",
    "\n",
    "    def build_generator(self, maxlen, batchsize=1):\n",
    "            \n",
    "            img = tf.placeholder(tf.float32, [self.batch_size, self.dim_in])\n",
    "            image_embedding = tf.matmul(img, self.img_embedding) + self.img_embedding_bias\n",
    "            state = self.lstm.zero_state(batchsize, dtype=tf.float32)\n",
    "\n",
    "            all_words = []\n",
    "            with tf.variable_scope(\"RNN\"):\n",
    "                output, state = self.lstm(image_embedding, state)\n",
    "                previous_word = tf.nn.embedding_lookup(self.word_embedding, [0]) + self.embedding_bias\n",
    "\n",
    "                i=0\n",
    "                while(i<maxlen):\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "                    out, state = self.lstm(previous_word, state)\n",
    "\n",
    "                    logit = tf.matmul(out, self.word_encoding) + self.word_encoding_bias\n",
    "                    best_word = tf.argmax(logit, 1)\n",
    "\n",
    "                    previous_word = tf.nn.embedding_lookup(self.word_embedding, best_word)\n",
    "                    previous_word += self.embedding_bias\n",
    "\n",
    "                    all_words.append(best_word)\n",
    "                    i=i+1\n",
    "\n",
    "            return img, all_words\n",
    "\n",
    "####################Training RNN##################\n",
    "dim_embed = 256\n",
    "dim_hidden = 256\n",
    "dim_in = 10\n",
    "batch_size = 128\n",
    "momentum = 0.9\n",
    "n_epochs = 100\n",
    "\n",
    "\n",
    "def train(learning_rate=0.001, continue_training=False, transfer=True):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    #feats=data_input\n",
    "    #captions=data_output\n",
    "    #print(captions[0].lstrip())\n",
    "    wordtoix, ixtoword, init_b = preProBuildWordVocab(captions)\n",
    "    np.save('ixtoword.npy', ixtoword)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    n_words = len(wordtoix)\n",
    "    maxlen = np.max( [x for x in map(lambda x: len(x.split(' ')), captions) ] )\n",
    "    caption_generator = Captions(dim_in, dim_hidden, dim_embed, batch_size, maxlen+2, n_words, init_b)\n",
    "\n",
    "    loss, image, sentence, mask = caption_generator.build_model()\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    # print(loss)\n",
    "    # print(sentence)\n",
    "    # print(mask)\n",
    "    # print(image)\n",
    "    # print(maxlen)\n",
    "    # #np.save('data/ixtoword', ixtoword)\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate, global_step,int(len(feats) / batch_size), 0.95)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        for start, end in zip(range(0, len(feats), batch_size), range(batch_size, len(feats), batch_size)):\n",
    "\n",
    "            current_feats = feats[start:end]\n",
    "            current_captions = captions[start:end]\n",
    "            current_caption_ind = [x for x in map(lambda cap: [wordtoix[word] for word in cap.lower().split(' ')[:-1] if word in wordtoix],current_captions)]\n",
    "\n",
    "            current_caption_matrix = sequence.pad_sequences(current_caption_ind, padding='post', maxlen=maxlen + 1)\n",
    "            current_caption_matrix = np.hstack([np.full((len(current_caption_matrix), 1), 0), current_caption_matrix])\n",
    "\n",
    "            current_mask_matrix = np.zeros((current_caption_matrix.shape[0], current_caption_matrix.shape[1]))\n",
    "            nonzeros = np.array([x for x in map(lambda x: (x != 0).sum() + 2, current_caption_matrix)])\n",
    "\n",
    "            for ind, row in enumerate(current_mask_matrix):\n",
    "                row[:nonzeros[ind]] = 1\n",
    "\n",
    "            _, loss_value = sess.run([train_op, loss], feed_dict={\n",
    "                image: current_feats.astype(np.float32),\n",
    "                sentence: current_caption_matrix.astype(np.int32),\n",
    "                mask: current_mask_matrix.astype(np.float32)\n",
    "            })\n",
    "\n",
    "        print(\"Avg loss: \", loss_value, \"\\t Epoch {}/{}\".format(epoch, n_epochs))\n",
    "        saver.save(sess, os.path.join(model_path, 'model'), global_step=epoch)\n",
    "        if(loss_value<=2.1):\n",
    "            break\n",
    "\n",
    "        #print(\"Saving the model from epoch: \", epoch)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "a82bSlUqX7tm",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "train(0.001,False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "vjxjV5-7aiU2",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "  dim_embed = 256\n",
    "  dim_hidden = 256\n",
    "  dim_in = 10\n",
    "  batch_size = 1\n",
    "  learning_rate = 0.001\n",
    "  momentum = 0.9\n",
    "  #n_epochs = 25\n",
    "  wordtoix, ixtoword, init_b = preProBuildWordVocab(captions)\n",
    "  np.save('ixtoword.npy', ixtoword)\n",
    "  \n",
    "  n_words = len(ixtoword)\n",
    "  maxlen=29\n",
    "   \n",
    "  tf.reset_default_graph()\n",
    "  sess = tf.InteractiveSession()\n",
    "   \n",
    "  caption_generator = Captions(dim_in, dim_hidden, dim_embed, batch_size, maxlen+2, n_words,None)\n",
    "\n",
    "  image, generated_words = caption_generator.build_generator(maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "66RDUOAPyH2a",
    "colab_type": "code",
    "outputId": "d48298ce-7375-4242-f286-56c69c105b85",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/models/tensorflow/model-41\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_captions=[]\n",
    "  \n",
    "#data_input=np.load('/content/gdrive/My Drive/data_input_vgg.npz')['name1']\n",
    "#data_output=np.load('/content/gdrive/My Drive/data_output_vgg.npz')['name1']\n",
    "\n",
    "data_input_test=np.load('/content/gdrive/My Drive/data_input_goog_train_4.npz')['name1']\n",
    "data_output_test=np.load('/content/gdrive/My Drive/data_output_vgg.npz')['name1']\n",
    "\n",
    "feats=data_input_test\n",
    "captions=data_output_test\n",
    "\n",
    "# data_input=np.load('/content/gdrive/My Drive/feats.npy','r')\n",
    "# #data_output=np.load('/content/gdrive/My Drive/data_output_vgg.npz')['name1']\n",
    "\n",
    "# feats=data_input\n",
    "# #captions=data_output\n",
    "\n",
    "# annotation_path='/content/gdrive/My Drive/results_20130124.token'\n",
    "# annotations = pd.read_table(annotation_path, sep='\\t', header=None, names=['image', 'caption'])\n",
    "# data_output=annotations['caption'].values\n",
    "# captions=data_output\n",
    "    \n",
    "saver = tf.train.Saver()\n",
    "saved_path=tf.train.latest_checkpoint(model_path)\n",
    "saver.restore(sess, saved_path)\n",
    "\n",
    "def test(sess,image,generated_words,ixtoword,idx):\n",
    "\n",
    "    feat = np.array([feats[idx]])\n",
    "\n",
    "    generated_word_index= sess.run(generated_words, feed_dict={image:feat})\n",
    "    generated_word_index = np.hstack(generated_word_index)\n",
    "\n",
    "    generated_sentence = [ixtoword[x] for x in generated_word_index]\n",
    "    #print(generated_sentence)\n",
    "    sen=[]\n",
    "    for j in range(0,len(generated_sentence)):\n",
    "      if(generated_sentence[j]!='.'):\n",
    "        sen.append(generated_sentence[j])\n",
    "      if(generated_sentence[j]=='.'):\n",
    "        break\n",
    "    predicted_captions.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "fi4qIKEoyE0H",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "#predicted_captions=[]\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "data_input_test=np.load('/content/gdrive/My Drive/data_input_goog_train_4.npz')['name1']\n",
    "data_output_test=np.load('/content/gdrive/My Drive/data_output_vgg.npz')['name1']\n",
    "\n",
    "feats_test=data_input_test\n",
    "captions_test=data_output_test\n",
    "\n",
    "for i in range(0,len(feats_test)):\n",
    "  test(sess,image,generated_words,ixtoword,i)\n",
    "  if(i%1000==0):\n",
    "    print(i)\n",
    "\n",
    "capt=[]\n",
    "pred=[]\n",
    "c=0\n",
    "\n",
    "for i in range(0,len(feats_test)-5,5):\n",
    "  li=[]\n",
    "  for j in range(i,i+5):\n",
    "     li.append(captions_test[j].split())\n",
    "  capt.append(li)\n",
    "  pred.append(predicted_captions[i])\n",
    "\n",
    "\n",
    "print(capt[2])\n",
    "print(pred[2])\n",
    "# print(len(capt))\n",
    "# print(len(pred))\n",
    "print('BLEU-1: %f' % corpus_bleu(capt, pred, weights=(1.0, 0, 0, 0)))\n",
    "print('BLEU-2: %f' % corpus_bleu(capt, pred, weights=(0.5, 0.5, 0, 0)))\n",
    "print('BLEU-3: %f' % corpus_bleu(capt, pred, weights=(0.3, 0.3, 0.3, 0)))\n",
    "print('BLEU-4: %f' % corpus_bleu(capt, pred, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "#print(captions[0].split())\n",
    "#print(captions[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "30ZE8U70DHLc",
    "colab_type": "code",
    "outputId": "fb8a37c9-429e-4caf-871d-c2f3098b88e7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229.0
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c8ceeeaa92b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m996\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m996\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'capt' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(capt[996])\n",
    "print(pred[996])\n",
    "\n",
    "#Train\n",
    "#2\n",
    "#1000\n",
    "#996\n",
    "#10590\n",
    "\n",
    "\n",
    "#Test\n",
    "#0\n",
    "#10\n",
    "#25\n",
    "#200\n",
    "#1000"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Task_4_VLAD.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
