{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GEutyvKHb3hd",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow\n",
    "!pip install -q sklearn\n",
    "!pip install -q torch\n",
    "!pip install -q pretrainedmodels\n",
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "kEfCahUVFGvF",
    "colab_type": "code",
    "outputId": "f286222a-9a35-4d4f-a3b8-6249083dae68",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JCfij5DIWEq1",
    "colab_type": "code",
    "outputId": "ed63609d-9bf5-49bd-cfd7-9a6bc17dadae",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man sitting in a racing car with black sunglasses and a look that reads \" I 'm ready to win . \"\n"
     ]
    }
   ],
   "source": [
    "#import pretrainedmodels\n",
    "import torch\n",
    "#import pretrainedmodels.utils as utils\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "############################################Encoder#################################################\n",
    "#model_name = 'vgg16' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "#print(pretrainedmodels.pretrained_settings[model_name])\n",
    "#model.eval()\n",
    "\n",
    "# with open('./8/8/8.txt') as f:\n",
    "#     content = [x.strip('\\n') for x in f.readlines()]\n",
    "\n",
    "# print(content[0].split(\"|\")[0])\n",
    "# str1='./8/train_8/'\n",
    "\n",
    "data_input=[]\n",
    "data_output=[]\n",
    "\n",
    "for i in range(0,len(content)):\n",
    "    try:\n",
    "        str2=content[i].split(\"|\")[0]\n",
    "        str3=str1+str2\n",
    "        #print(str3)\n",
    "        load_img = utils.LoadImage()\n",
    "\n",
    "        # transformations depending on the model\n",
    "        # rescale, center crop, normalize, and others (ex: ToBGR, ToRange255)\n",
    "        tf_img = utils.TransformImage(model)\n",
    "\n",
    "        path_img = str3\n",
    "\n",
    "        input_img = load_img(path_img)\n",
    "        input_tensor = tf_img(input_img)  \n",
    "        input_tensor = input_tensor.unsqueeze(0)\n",
    "        input = torch.autograd.Variable(input_tensor,\n",
    "                                        requires_grad=False)\n",
    "\n",
    "        features = model.features(input)\n",
    "        features = torch.Tensor.detach(features).numpy()\n",
    "        data_input.append(features[0])\n",
    "        capt=content[i].split(\"|\")[2].lstrip()\n",
    "        data_output.append(capt)\n",
    "\n",
    "        if(i%100==0):\n",
    "            print(i)\n",
    "\n",
    "        if(i%1000==0):\n",
    "          np.savez('data_input_vgg.npz', name1=data_input)\n",
    "          np.savez('data_output_vgg.npz', name1=data_output)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#Normalization\n",
    "# data_input=np.array(data_input)\n",
    "# print(data_input)\n",
    "# for i in range (0,4096):\n",
    "#    data_input[:,i]=minmax_scale(data_input[:,i])\n",
    "\n",
    "# print(data_input[0])\n",
    "# print(data_input[1])\n",
    "#data_input=np.load('/content/gdrive/My Drive/feats.npy','r')\n",
    "\n",
    "data_input=np.load('/content/gdrive/My Drive/data_input_goog_train_3.npz')['name1']\n",
    "data_output=np.load('/content/gdrive/My Drive/data_output_vgg.npz')['name1']\n",
    "\n",
    "data_input_test=np.load('/content/gdrive/My Drive/data_input_goog_test_3.npz')['name1']\n",
    "data_output_test=np.load('/content/gdrive/My Drive/data_output_vgg_test.npz')['name1']\n",
    "\n",
    "feats_test=data_input_test\n",
    "captions_test=data_output_test\n",
    "\n",
    "feats_tot=data_input\n",
    "captions_tot=data_output\n",
    "\n",
    "feats=feats_tot\n",
    "captions=captions_tot\n",
    "\n",
    "print(data_output[0])\n",
    "\n",
    "l# print(data_input[10],data_output[10])\n",
    "# print(data_input1[10],data_output1[10])\n",
    "# print(len(data_input),len(data_input[0]))\n",
    "# print(len(data_output),len(data_output[0]))\n",
    "\n",
    "############################################################Decoder################################\n",
    "\n",
    "model_path = '/content/gdrive/My Drive/models/tensorflow'\n",
    "\n",
    "#################Processing words###############\n",
    "def preProBuildWordVocab(sentence_iterator, word_count_threshold=15): \n",
    "    print('preprocessing %d word vocab' % (word_count_threshold, ))\n",
    "    word_counts = {}\n",
    "    nsents = 0\n",
    "    for sent in sentence_iterator:\n",
    "      nsents += 1\n",
    "      for w in sent.lower().split(' '):\n",
    "        word_counts[w] = word_counts.get(w, 0) + 1\n",
    "    vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "    print('preprocessed words %d -> %d' % (len(word_counts), len(vocab)))\n",
    "\n",
    "    ixtoword = {}\n",
    "    ixtoword[0] = '.'\n",
    "    wordtoix = {}\n",
    "    wordtoix['#START#'] = 0\n",
    "    ix = 1\n",
    "    for w in vocab:\n",
    "      wordtoix[w] = ix\n",
    "      ixtoword[ix] = w\n",
    "      ix += 1\n",
    "\n",
    "    word_counts['.'] = nsents\n",
    "    bias_init_vector = np.array([1.0*word_counts[ixtoword[i]] for i in ixtoword])\n",
    "    bias_init_vector /= np.sum(bias_init_vector)\n",
    "    bias_init_vector = np.log(bias_init_vector)\n",
    "    bias_init_vector -= np.max(bias_init_vector)\n",
    "    return wordtoix, ixtoword, bias_init_vector.astype(np.float32)\n",
    "\n",
    "\n",
    "class Captions():\n",
    "    \n",
    "    def initialize_param(self,init_b):\n",
    "        with tf.device('/cpu:0'):\n",
    "            self.word_embedding = tf.Variable(tf.random_uniform([self.n_words, self.dim_embed], -0.1, 0.1))\n",
    "\n",
    "            self.embedding_bias = tf.Variable(tf.zeros([dim_embed]))\n",
    "            self.lstm = tf.contrib.rnn.BasicLSTMCell(dim_hidden)\n",
    "\n",
    "            self.img_embedding = tf.Variable(tf.random_uniform([dim_in, dim_hidden], -0.1, 0.1))\n",
    "            self.img_embedding_bias = tf.Variable(tf.zeros([dim_hidden]))\n",
    "\n",
    "            self.word_encoding = tf.Variable(tf.random_uniform([dim_hidden, self.n_words], -0.1, 0.1))\n",
    "            \n",
    "            if init_b is not None:\n",
    "              self.word_encoding_bias = tf.Variable(init_b)\n",
    "            else:\n",
    "              self.word_encoding_bias = tf.Variable(tf.zeros([n_words]))\n",
    " \n",
    "\n",
    "    def __init__(self,dim_in, dim_embed, dim_hidden, batch_size,steps, n_words, init_b):\n",
    "\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_embed = dim_embed\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.batch_size = batch_size\n",
    "        self.n_lstm_steps = steps\n",
    "        self.n_words = n_words\n",
    "\n",
    "        self.initialize_param(init_b)\n",
    "        \n",
    "    def build_model(self):\n",
    "            caption_placeholder = tf.placeholder(tf.int32, [self.batch_size, self.n_lstm_steps])\n",
    "            mask = tf.placeholder(tf.float32, [self.batch_size, self.n_lstm_steps])\n",
    "\n",
    "            img = tf.placeholder(tf.float32, [self.batch_size, self.dim_in])\n",
    "\n",
    "            image_embedding = tf.matmul(img, self.img_embedding) + self.img_embedding_bias\n",
    "\n",
    "            state = self.lstm.zero_state(self.batch_size, dtype=tf.float32)\n",
    "\n",
    "            total_loss = 0.0\n",
    "            \n",
    "            with tf.variable_scope(\"RNN\"):\n",
    "                i=0\n",
    "                while(i<self.n_lstm_steps):\n",
    "                    if i > 0:\n",
    "                        with tf.device('/cpu:0'):\n",
    "                          current_embedding = tf.nn.embedding_lookup(self.word_embedding,caption_placeholder[:, i - 1]) + self.embedding_bias\n",
    "                          tf.get_variable_scope().reuse_variables()\n",
    "                    else:\n",
    "                        current_embedding = image_embedding\n",
    "                        \n",
    "                    out, state = self.lstm(current_embedding, state)\n",
    "\n",
    "                    if i > 0:\n",
    "                        labels = tf.expand_dims(caption_placeholder[:, i], 1)\n",
    "                        ix_range = tf.range(0, self.batch_size, 1)\n",
    "                        ixs = tf.expand_dims(ix_range, 1)\n",
    "                        concat = tf.concat([ixs, labels], 1)\n",
    "                        onehot = tf.sparse_to_dense(\n",
    "                            concat, tf.stack([self.batch_size, self.n_words]), 1.0, 0.0)\n",
    "\n",
    "                        logit = tf.matmul(out, self.word_encoding) + self.word_encoding_bias\n",
    "                        xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=onehot)\n",
    "                        xentropy = xentropy * mask[:, i]\n",
    "\n",
    "                        loss = tf.reduce_sum(xentropy)\n",
    "                        total_loss += loss\n",
    "                    \n",
    "                    i=i+1\n",
    "\n",
    "                total_loss = total_loss / tf.reduce_sum(mask[:, 1:])\n",
    "                return total_loss, img, caption_placeholder, mask\n",
    "\n",
    "    def build_generator(self, maxlen, batchsize=1):\n",
    "            \n",
    "            img = tf.placeholder(tf.float32, [self.batch_size, self.dim_in])\n",
    "            image_embedding = tf.matmul(img, self.img_embedding) + self.img_embedding_bias\n",
    "            state = self.lstm.zero_state(batchsize, dtype=tf.float32)\n",
    "\n",
    "            all_words = []\n",
    "            with tf.variable_scope(\"RNN\"):\n",
    "                output, state = self.lstm(image_embedding, state)\n",
    "                previous_word = tf.nn.embedding_lookup(self.word_embedding, [0]) + self.embedding_bias\n",
    "\n",
    "                i=0\n",
    "                while(i<maxlen):\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "                    out, state = self.lstm(previous_word, state)\n",
    "\n",
    "                    logit = tf.matmul(out, self.word_encoding) + self.word_encoding_bias\n",
    "                    best_word = tf.argmax(logit, 1)\n",
    "\n",
    "                    previous_word = tf.nn.embedding_lookup(self.word_embedding, best_word)\n",
    "                    previous_word += self.embedding_bias\n",
    "\n",
    "                    all_words.append(best_word)\n",
    "                    i=i+1\n",
    "\n",
    "            return img, all_words\n",
    "\n",
    "####################Training RNN##################\n",
    "dim_embed = 256\n",
    "dim_hidden = 256\n",
    "dim_in = 2048\n",
    "batch_size = 128\n",
    "momentum = 0.9\n",
    "n_epochs = 100\n",
    "\n",
    "\n",
    "def train(learning_rate=0.001, continue_training=False, transfer=True):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    #feats=data_input\n",
    "    #captions=data_output\n",
    "    #print(captions[0].lstrip())\n",
    "    wordtoix, ixtoword, init_b = preProBuildWordVocab(captions)\n",
    "    np.save('ixtoword.npy', ixtoword)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    n_words = len(wordtoix)\n",
    "    maxlen = np.max( [x for x in map(lambda x: len(x.split(' ')), captions) ] )\n",
    "    caption_generator = Captions(dim_in, dim_hidden, dim_embed, batch_size, maxlen+2, n_words, init_b)\n",
    "\n",
    "    loss, image, sentence, mask = caption_generator.build_model()\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    # print(loss)\n",
    "    # print(sentence)\n",
    "    # print(mask)\n",
    "    # print(image)\n",
    "    # print(maxlen)\n",
    "    # #np.save('data/ixtoword', ixtoword)\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate, global_step,int(len(feats) / batch_size), 0.95)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        for start, end in zip(range(0, len(feats), batch_size), range(batch_size, len(feats), batch_size)):\n",
    "\n",
    "            current_feats = feats[start:end]\n",
    "            current_captions = captions[start:end]\n",
    "            current_caption_ind = [x for x in map(lambda cap: [wordtoix[word] for word in cap.lower().split(' ')[:-1] if word in wordtoix],current_captions)]\n",
    "\n",
    "            current_caption_matrix = sequence.pad_sequences(current_caption_ind, padding='post', maxlen=maxlen + 1)\n",
    "            current_caption_matrix = np.hstack([np.full((len(current_caption_matrix), 1), 0), current_caption_matrix])\n",
    "\n",
    "            current_mask_matrix = np.zeros((current_caption_matrix.shape[0], current_caption_matrix.shape[1]))\n",
    "            nonzeros = np.array([x for x in map(lambda x: (x != 0).sum() + 2, current_caption_matrix)])\n",
    "\n",
    "            for ind, row in enumerate(current_mask_matrix):\n",
    "                row[:nonzeros[ind]] = 1\n",
    "\n",
    "            _, loss_value = sess.run([train_op, loss], feed_dict={\n",
    "                image: current_feats.astype(np.float32),\n",
    "                sentence: current_caption_matrix.astype(np.int32),\n",
    "                mask: current_mask_matrix.astype(np.float32)\n",
    "            })\n",
    "\n",
    "        print(\"Avg loss: \", loss_value, \"\\t Epoch {}/{}\".format(epoch, n_epochs))\n",
    "        saver.save(sess, os.path.join(model_path, 'model'), global_step=epoch)\n",
    "        if(loss_value<=2.1):\n",
    "            break\n",
    "\n",
    "        #print(\"Saving the model from epoch: \", epoch)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "a82bSlUqX7tm",
    "colab_type": "code",
    "outputId": "aa0e4789-b1d1-4608-e414-eccd8623ba9b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing 15 word vocab\n",
      "preprocessed words 14136 -> 2708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss:  3.480961 \t Epoch 0/100\n",
      "Avg loss:  3.1828113 \t Epoch 1/100\n",
      "Avg loss:  3.0210776 \t Epoch 2/100\n",
      "Avg loss:  2.9261062 \t Epoch 3/100\n",
      "Avg loss:  2.8503425 \t Epoch 4/100\n",
      "Avg loss:  2.785673 \t Epoch 5/100\n",
      "Avg loss:  2.744398 \t Epoch 6/100\n",
      "Avg loss:  2.6691751 \t Epoch 7/100\n",
      "Avg loss:  2.6439848 \t Epoch 8/100\n",
      "Avg loss:  2.61354 \t Epoch 9/100\n",
      "Avg loss:  2.5650616 \t Epoch 10/100\n",
      "Avg loss:  2.5374012 \t Epoch 11/100\n",
      "Avg loss:  2.507603 \t Epoch 12/100\n",
      "Avg loss:  2.4665754 \t Epoch 13/100\n",
      "Avg loss:  2.4413068 \t Epoch 14/100\n",
      "Avg loss:  2.403728 \t Epoch 15/100\n",
      "Avg loss:  2.392152 \t Epoch 16/100\n",
      "Avg loss:  2.3591044 \t Epoch 17/100\n",
      "Avg loss:  2.3358681 \t Epoch 18/100\n",
      "Avg loss:  2.3263166 \t Epoch 19/100\n",
      "Avg loss:  2.2848492 \t Epoch 20/100\n",
      "Avg loss:  2.2757018 \t Epoch 21/100\n",
      "Avg loss:  2.2558494 \t Epoch 22/100\n",
      "Avg loss:  2.2297387 \t Epoch 23/100\n",
      "Avg loss:  2.205616 \t Epoch 24/100\n",
      "Avg loss:  2.1905503 \t Epoch 25/100\n",
      "Avg loss:  2.1868587 \t Epoch 26/100\n",
      "Avg loss:  2.151852 \t Epoch 27/100\n",
      "Avg loss:  2.1256146 \t Epoch 28/100\n",
      "Avg loss:  2.1030004 \t Epoch 29/100\n",
      "Avg loss:  2.0975695 \t Epoch 30/100\n"
     ]
    }
   ],
   "source": [
    "train(0.001,False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "vjxjV5-7aiU2",
    "colab_type": "code",
    "outputId": "91c4d7b7-0cd2-45bc-b5e9-2a8edee2c891",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing 15 word vocab\n",
      "preprocessed words 14136 -> 2708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "  dim_embed = 256\n",
    "  dim_hidden = 256\n",
    "  dim_in = 2048\n",
    "  batch_size = 1\n",
    "  learning_rate = 0.001\n",
    "  momentum = 0.9\n",
    "  #n_epochs = 25\n",
    "  wordtoix, ixtoword, init_b = preProBuildWordVocab(captions)\n",
    "  np.save('ixtoword.npy', ixtoword)\n",
    "  \n",
    "  n_words = len(ixtoword)\n",
    "  maxlen=29\n",
    "   \n",
    "  tf.reset_default_graph()\n",
    "  sess = tf.InteractiveSession()\n",
    "   \n",
    "  caption_generator = Captions(dim_in, dim_hidden, dim_embed, batch_size, maxlen+2, n_words,None)\n",
    "\n",
    "  image, generated_words = caption_generator.build_generator(maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "66RDUOAPyH2a",
    "colab_type": "code",
    "outputId": "7bae532f-3b17-443f-8490-b028d22557ce",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/models/tensorflow/model-30\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_captions=[]\n",
    "  \n",
    "#data_input=np.load('/content/gdrive/My Drive/data_input_vgg.npz')['name1']\n",
    "#data_output=np.load('/content/gdrive/My Drive/data_output_vgg.npz')['name1']\n",
    "\n",
    "data_input_test=np.load('/content/gdrive/My Drive/data_input_goog_train_3.npz')['name1']\n",
    "data_output_test=np.load('/content/gdrive/My Drive/data_output_vgg.npz')['name1']\n",
    "\n",
    "feats=data_input_test\n",
    "captions=data_output_test\n",
    "\n",
    "# data_input=np.load('/content/gdrive/My Drive/feats.npy','r')\n",
    "# #data_output=np.load('/content/gdrive/My Drive/data_output_vgg.npz')['name1']\n",
    "\n",
    "# feats=data_input\n",
    "# #captions=data_output\n",
    "\n",
    "# annotation_path='/content/gdrive/My Drive/results_20130124.token'\n",
    "# annotations = pd.read_table(annotation_path, sep='\\t', header=None, names=['image', 'caption'])\n",
    "# data_output=annotations['caption'].values\n",
    "# captions=data_output\n",
    "    \n",
    "saver = tf.train.Saver()\n",
    "saved_path=tf.train.latest_checkpoint(model_path)\n",
    "saver.restore(sess, saved_path)\n",
    "\n",
    "def test(sess,image,generated_words,ixtoword,idx):\n",
    "\n",
    "    feat = np.array([feats[idx]])\n",
    "    sanity_check= False\n",
    "\n",
    "    generated_word_index= sess.run(generated_words, feed_dict={image:feat})\n",
    "    generated_word_index = np.hstack(generated_word_index)\n",
    "\n",
    "    generated_sentence = [ixtoword[x] for x in generated_word_index]\n",
    "    #print(generated_sentence)\n",
    "    sen=[]\n",
    "    for j in range(0,len(generated_sentence)):\n",
    "      if(generated_sentence[j]!='.'):\n",
    "        sen.append(generated_sentence[j])\n",
    "      if(generated_sentence[j]=='.'):\n",
    "        break\n",
    "    predicted_captions.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "fi4qIKEoyE0H",
    "colab_type": "code",
    "outputId": "d95e24e9-0765-4a43-fb8b-db04b9c9599a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1398.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "[['A', 'woman', 'in', 'a', 'red', 'dress', 'is', 'singing', 'on', 'a', 'stage', 'next', 'to', 'three', 'men', 'playing', 'instruments', '.'], ['three', 'men', 'dressed', 'in', 'blue', 'play', 'guitar', 'while', 'a', 'woman', 'sings', '.'], ['A', 'music', 'group', 'performs', 'while', 'dressed', 'up', '.'], ['a', 'band', 'performing', 'at', 'a', 'show', '.'], ['A', 'band', 'performing', 'on', 'a', 'stage']]\n",
      "['a', 'band', 'performs', 'on', 'stage']\n",
      "BLEU-1: 0.487316\n",
      "BLEU-2: 0.301985\n",
      "BLEU-3: 0.218208\n",
      "BLEU-4: 0.111466\n"
     ]
    }
   ],
   "source": [
    "#predicted_captions=[]\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "data_input_test=np.load('/content/gdrive/My Drive/data_input_goog_train_3.npz')['name1']\n",
    "data_output_test=np.load('/content/gdrive/My Drive/data_output_vgg.npz')['name1']\n",
    "\n",
    "feats_test=data_input_test\n",
    "captions_test=data_output_test\n",
    "\n",
    "for i in range(0,len(feats_test)):\n",
    "  test(sess,image,generated_words,ixtoword,i)\n",
    "  if(i%1000==0):\n",
    "    print(i)\n",
    "\n",
    "capt=[]\n",
    "pred=[]\n",
    "c=0\n",
    "\n",
    "for i in range(0,len(feats_test)-5,5):\n",
    "  li=[]\n",
    "  for j in range(i,i+5):\n",
    "     li.append(captions_test[j].split())\n",
    "  capt.append(li)\n",
    "  pred.append(predicted_captions[i])\n",
    "\n",
    "\n",
    "print(capt[2])\n",
    "print(pred[2])\n",
    "# print(len(capt))\n",
    "# print(len(pred))\n",
    "print('BLEU-1: %f' % corpus_bleu(capt, pred, weights=(1.0, 0, 0, 0)))\n",
    "print('BLEU-2: %f' % corpus_bleu(capt, pred, weights=(0.5, 0.5, 0, 0)))\n",
    "print('BLEU-3: %f' % corpus_bleu(capt, pred, weights=(0.3, 0.3, 0.3, 0)))\n",
    "print('BLEU-4: %f' % corpus_bleu(capt, pred, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "#print(captions[0].split())\n",
    "#print(captions[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "tJIAT0FZ3LhO",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "30ZE8U70DHLc",
    "colab_type": "code",
    "outputId": "63c444a3-712f-468e-9972-92d3de35aca8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'man', 'sits', 'on', 'a', 'bench', 'beside', 'his', 'bike', 'while', 'viewing', 'the', 'scenery', 'around', 'him', 'overlooking', 'a', 'busy', 'city', '.'], ['An', 'overweight', 'man', 'in', 'shorts', 'is', 'sitting', 'on', 'a', 'bench', 'next', 'to', 'a', 'bicycle', '.'], ['A', 'man', 'is', 'sitting', 'on', 'a', 'bench', 'with', 'his', 'bike', 'outside', 'of', 'the', 'city', '.'], ['A', 'man', 'sitting', 'on', 'a', 'bench', 'next', 'to', 'a', 'bicycle', '.'], ['Man', 'sitting', 'on', 'bench', 'next', 'to', 'bike', '.']]\n",
      "['a', 'man', 'in', 'a', 'white', 'shirt', 'and', 'jeans', 'is', 'walking', 'down', 'a', 'sidewalk']\n"
     ]
    }
   ],
   "source": [
    "print(capt[1000])\n",
    "print(pred[1000])\n",
    "\n",
    "#Train\n",
    "#2\n",
    "#1000\n",
    "#996\n",
    "#10590\n",
    "\n",
    "\n",
    "#Test\n",
    "#0\n",
    "#10\n",
    "#25\n",
    "#200\n",
    "#1000"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Task_3_GoogLeNet.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
